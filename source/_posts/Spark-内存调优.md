---
title: Spark 内存调优
date: 2017-05-31 11:50:28
tags: Spark
categories: 大数据
---

Spark 是基于内存的，所以合理地管理内存会提高程序的性能。想要有效地管理内存，就要知道对象占用了多少内存，访问对象的开销以及 GC 的执行情况。

首先，要知道对象占了多少内存，我们需要清楚有哪些地方会消耗掉内存。默认情况下，Java 访问对象很快，但是消耗的空间是原生数据类型2-5倍。

* 每个的对象都有一个“对象头”，对象头大约 16 个字节，包含类似指向类的指针信息。如果一个对象很小，对象头可能比对象包含的数据还要大。
* Java 的 String 在原始的 String 数据上会额外占用大约 40 字节 ，用来存储如长度之类的信息。由于 Java 使用 UTF-16 编码，所以每个字符会占用 2 个字节。一个 10 个字符的 String 大概会占用 60 个字节。
* HashMap 和 LinkedList 这样常见的数据结构使用了链表数据结构，每一个 entry 都是一个包装对象，这些对象不光包含对象头，还包含了指向下一个对象的引用，这个引用会额外占用 8 个字节。
* 常见的原始数据类型集合都会以包装类形式存储，比如 Integer。

因此，降低内存消耗的一种方法是不使用带有头和额外开销的数据结构。比如

* 使用数组和原始数据类型代替集合和包装类。
* 尽量避免嵌套的数据结构。
* 使用数值型和枚举型代替字符串作为id。
* 对于内存小于 32 G的机器，使用 JVM 的 -XX:+UseCompressedOops 参数限制引用长度为 4 字节。

在 Spark 中内存被用来执行计算（shuffle、join、sort、aggregations）和存储数据（缓存和广播数据）。执行计算和存储数据使用的是同一块区域，如果执行计算的内存没有被使用，存储数据可以占用这些内存，反之，执行计算也可以使用没有被存储占用的内存。如果一个程序没有使用缓存，那么程序可以将所有内存用来执行计算。虽然执行计算可以释放存储以获取更多的内存，但是缓存在不超过阈值的情况下，是不会被释放的。

关于内存的划分，Spark 提供了两个参数，但大多数场景下，用户是不需要调整 Spark 的配置的。

* spark.memory.fraction 
* spark.memory.storageFraction



当您的程序中存储的RDDs有很大的“搅动”时，JVM垃圾收集可能会成为一个问题。(这通常不是一个问题，只需要读取一次RDD，然后在它上运行许多操作。)当Java需要清除旧对象为新对象腾出空间时，它需要跟踪所有的Java对象并找到未使用的对象。这里要记住的要点是，垃圾收集的成本与Java对象的数量成比例，所以使用较少对象的数据结构(例如，一个Ints数组而不是一个LinkedList)可以大大降低这个成本。一种更好的方法是将对象持久化到序列化的形式中，如上所述:现在每个RDD分区只会有一个对象(一个字节数组)。在尝试其他技术之前，如果GC是一个问题，首先要尝试的是使用序列化的缓存。

GC调优的第一步是收集有关垃圾收集发生频率和花费的时间的统计信息。这可以通过添加 -verbose:gc -XX:+PrintGCDetails -XX:+printgctimetstamp选项来完成。

在进行调优之前，需要了解 Java 的GC模型。

* Java堆空间分为两个区域，分别是年轻的和年老的。年轻一代的目标是持有寿命较短的物体，而老一代则是为具有较长寿命的物体而设计的
* 年轻一代被进一步划分为三个区域:Eden, Survivor1, Survivor2
* 对垃圾收集过程的一个简化描述:当伊甸园满时，一个小的GC会在伊甸园中运行，而从Eden中存活的对象和存活者则被复制到生存环境中。幸存者区域被交换了。如果一个对象足够大，或者生存环境已经满，那么它就会被移动到旧的。最后，当Old接近饱和时，将调用一个完整的GC。

在Spark中，GC调优的目标是确保只存储在旧的一代中，并且年轻的一代足够大，可以存储短时间的对象。这将有助于避免在任务执行期间收集创建的临时对象。









