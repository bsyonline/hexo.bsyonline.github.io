---
title: project schema evolution
tags:
  - untag
category:
  - uncategory
author: bsyonline
lede: 没有摘要
date: 2019-05-19 22:36:57
thumbnail:
---



#### 阶段一 
目标： 快速提供变更比对服务
2016年2-3月，使用java多线程处理hdfs上的外部数据，存储到hbase，通过api提供服务
问题：主要问题是数据处理的效率问题

#### 阶段二
目标：主要目标解决推送效率和处理规模问题
从2017年1月开始调研数据处理的，对比了hadoop，spring-batch和spark，最后选择spark作为数据处理框架，到17年4月完成升级，数据频次从一周一次提高到一天一次。
服务层使用spring boot/spring cloud微服务架构。
问题：主要问题是数据质量问题，包括数据源数据问题，数据推送过快导致的数据和公示不一致的噪音数据

#### 阶段三
目标：解决数据质量问题，同时能够支持后续分析型产品需求。
2018年4月开始启动数据质量问题的处理方案设计，同时调研了一些OLAP工具比如apache kylin，流式数据处理工具spark streaming，spring cloud data flow，streamSet等，最后对数据处理结构和流程进行重新设计，数据层使用greenplum代替oracle，保留原来A-O-S表的处理过程，将原来处理流程中多处使用的相同比对逻辑合并并提前到O表之后，多个数据源数据进行参数检查后生成O表，生成O表数据之后用存储过程比对出变更，以变更表为基础，生成S表和拉链表，并更新上层业务库Mongo，es，neo4j。在生成变更表的环节加入爬虫网爬公示系统数据校验，保证数据质量。
第三阶段相比第二阶段，在产品的功能和服务质量上都有了很大提升，在原有数据服务的基础上，还能够支持用户提出SLA的质量保证。
另一方面在数据使用方面，原先我们内部并没有使用风铃的数据作为业务应用，所以并不知道用户在使用的时候有什么问题，我们给出去的数据好不好用。现在我们自己也有一些业务场景来使用数据，基于这些场景将我们使用数据的方式，手段在自己验证只有对用户也提供一些增值服务。比如，一些离线数据服务，原来用户在使用风铃的时候，根据风铃的变更数据，再调企业查询获取完整数据信息入库，现在我们可以根据变更数据生成对应语句，客户执行语句就可以增量完成更新数据库。
实验了一种ALL-IN的模式，将我们的内部跑的这些数据处理流程用docker放在一个机器或是硬盘上，在客户端用docker compose一键运行起来，然后接入到区块链的节点上，我们将数据定期更新到区块链的节点上，数据处理在客户端进行，完成后即可对客户提供服务。

#### 优化

##### 代码优化

1. SimpleDateFormat不是线程安全的，多线程环境下会有问题，使用 java8 的 date
2. 多个类库到单一类库，日志库，Json库
3. 

##### 业务优化

1. 缓存的使用，使用公共逻辑简化缓存使用，AOP+注解。
2. 水平拆分，公共代码变成公共服务，保证不出现水平调用。